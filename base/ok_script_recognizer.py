# -*- coding: utf-8 -*-
"""
OK Script åœ–åƒè¾¨è­˜æ•´åˆæ¨¡çµ„

æä¾›åŸºæ–¼ OK Script çš„ template matching åŠŸèƒ½ï¼Œ
å„ªå…ˆæ–¼ç¾æœ‰çš„ pyautogui åœ–ç‰‡è¾¨è­˜æ–¹æ³•ã€‚

çµ±è¨ˆåŠŸèƒ½ï¼š
- å‘½ä¸­ç‡ (Hit Rate)
- å¹³å‡è¾¨è­˜æ™‚é–“
- æ–¹æ³•å°æ¯”åˆ†æ
"""

import time
import os
import json
from datetime import datetime
from typing import Optional, Tuple, Dict, Any
from dataclasses import dataclass, field, asdict
from threading import Lock

# å˜—è©¦å°å…¥ OK Script
try:
    from ok import OK
    OK_SCRIPT_AVAILABLE = True
except ImportError:
    OK_SCRIPT_AVAILABLE = False

# å˜—è©¦å°å…¥ cv2 ç”¨æ–¼ template matching
try:
    import cv2
    import numpy as np
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

import pyautogui
from PIL import Image


@dataclass
class RecognitionResult:
    """è¾¨è­˜çµæœ"""
    success: bool
    method: str  # 'ok_script', 'pyautogui', 'ocr', 'coordinate'
    x: int = 0
    y: int = 0
    width: int = 0  # ç‰©ä»¶å¯¬åº¦ï¼ˆç”¨æ–¼ç´…æ¡†æ¨™è¨»ï¼‰
    height: int = 0  # ç‰©ä»¶é«˜åº¦ï¼ˆç”¨æ–¼ç´…æ¡†æ¨™è¨»ï¼‰
    confidence: float = 0.0
    time_ms: float = 0.0
    image_path: str = ""
    target_text: str = ""


@dataclass
class RecognitionStats:
    """è¾¨è­˜çµ±è¨ˆ"""
    total_attempts: int = 0
    ok_script_hits: int = 0
    ok_script_time_total: float = 0.0
    pyautogui_hits: int = 0
    pyautogui_time_total: float = 0.0
    ocr_hits: int = 0
    ocr_time_total: float = 0.0
    vlm_hits: int = 0
    vlm_time_total: float = 0.0
    coordinate_hits: int = 0
    
    # æ¯å€‹åœ–ç‰‡çš„çµ±è¨ˆ
    image_stats: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    
    def get_ok_script_hit_rate(self) -> float:
        """å–å¾— OK Script å‘½ä¸­ç‡"""
        if self.total_attempts == 0:
            return 0.0
        return self.ok_script_hits / self.total_attempts * 100
    
    def get_pyautogui_hit_rate(self) -> float:
        """å–å¾— pyautogui å‘½ä¸­ç‡"""
        if self.total_attempts == 0:
            return 0.0
        return self.pyautogui_hits / self.total_attempts * 100
    
    def get_vlm_hit_rate(self) -> float:
        """å–å¾— VLM å‘½ä¸­ç‡"""
        if self.total_attempts == 0:
            return 0.0
        return self.vlm_hits / self.total_attempts * 100
    
    def get_ok_script_avg_time(self) -> float:
        """å–å¾— OK Script å¹³å‡è¾¨è­˜æ™‚é–“ï¼ˆæ¯«ç§’ï¼‰"""
        if self.ok_script_hits == 0:
            return 0.0
        return self.ok_script_time_total / self.ok_script_hits
    
    def get_pyautogui_avg_time(self) -> float:
        """å–å¾— pyautogui å¹³å‡è¾¨è­˜æ™‚é–“ï¼ˆæ¯«ç§’ï¼‰"""
        if self.pyautogui_hits == 0:
            return 0.0
        return self.pyautogui_time_total / self.pyautogui_hits
    
    def get_vlm_avg_time(self) -> float:
        """å–å¾— VLM å¹³å‡è¾¨è­˜æ™‚é–“ï¼ˆæ¯«ç§’ï¼‰"""
        if self.vlm_hits == 0:
            return 0.0
        return self.vlm_time_total / self.vlm_hits


class OKScriptRecognizer:
    """
    OK Script åœ–åƒè¾¨è­˜å™¨
    
    å„ªå…ˆä½¿ç”¨ OK Script çš„ template matchingï¼Œ
    å¦‚æœå¤±æ•—å‰‡å›é€€åˆ° pyautoguiã€‚
    """
    
    _instance = None
    _lock = Lock()
    
    def __new__(cls):
        """å–®ä¾‹æ¨¡å¼"""
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
                cls._instance._initialized = False
            return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
        
        self._initialized = True
        self.stats = RecognitionStats()
        self.logger = None
        self._ok_script = None
        self._use_ok_script = True  # æ˜¯å¦å•Ÿç”¨ OK Script
        self._confidence_threshold = 0.7  # OK Script ä¿¡å¿ƒé–¾å€¼ï¼ˆé™ä½ä»¥æé«˜å°ç•«é¢è®ŠåŒ–çš„å®¹éŒ¯æ€§ï¼‰
        self._stats_file = "logs/recognition_stats.json"
        
        # è¿½è¹¤é€£çºŒåœ–åƒè¾¨è­˜å¤±æ•—æ¬¡æ•¸ï¼ˆç”¨æ–¼æ¸¬è©¦é©—è­‰ï¼‰
        self._consecutive_image_recognition_failures = 0
        
        # åˆå§‹åŒ– OK Script
        self._init_ok_script()
        
        # è¼‰å…¥æ­·å²çµ±è¨ˆ
        self._load_stats()
    
    def _init_ok_script(self):
        """åˆå§‹åŒ– OK Script"""
        if not OK_SCRIPT_AVAILABLE:
            if self.logger:
                self.logger.info("âš ï¸ OK Script æœªå®‰è£ï¼Œä½¿ç”¨ OpenCV template matching æ›¿ä»£")
            return
        
        try:
            self._ok_script = OK()
            if self.logger:
                self.logger.info("âœ… OK Script åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            if self.logger:
                self.logger.warning(f"âš ï¸ OK Script åˆå§‹åŒ–å¤±æ•—: {e}")
            self._ok_script = None
    
    def set_logger(self, logger):
        """è¨­ç½®æ—¥èªŒè¨˜éŒ„å™¨"""
        self.logger = logger
    
    def enable_ok_script(self, enabled: bool = True):
        """å•Ÿç”¨/åœç”¨ OK Script"""
        self._use_ok_script = enabled
    
    def set_confidence(self, confidence: float):
        """è¨­ç½®ä¿¡å¿ƒé–¾å€¼"""
        self._confidence_threshold = confidence
    
    def locate_on_screen(
        self,
        image_path: str,
        region: Tuple[int, int, int, int] = None,
        confidence: float = None
    ) -> Optional[RecognitionResult]:
        """
        åœ¨è¢å¹•ä¸Šå®šä½åœ–ç‰‡
        
        å„ªå…ˆç´šï¼šOK Script > pyautogui
        
        Args:
            image_path: åœ–ç‰‡è·¯å¾‘
            region: æœå°‹å€åŸŸ (left, top, width, height)
            confidence: ä¿¡å¿ƒé–¾å€¼ï¼ˆè¦†è“‹é è¨­å€¼ï¼‰
            
        Returns:
            RecognitionResult æˆ– None
        """
        if not os.path.exists(image_path):
            return None
        
        conf = confidence if confidence is not None else self._confidence_threshold
        self.stats.total_attempts += 1
        
        # è¨˜éŒ„åœ–ç‰‡çµ±è¨ˆ
        img_name = os.path.basename(image_path)
        if img_name not in self.stats.image_stats:
            self.stats.image_stats[img_name] = {
                'attempts': 0,
                'ok_script_hits': 0,
                'pyautogui_hits': 0,
                'ok_script_time': 0.0,
                'pyautogui_time': 0.0
            }
        self.stats.image_stats[img_name]['attempts'] += 1
        
        # ã€å„ªå…ˆç´š 1ã€‘OK Script / OpenCV Template Matching
        if self._use_ok_script:
            result = self._locate_with_ok_script(image_path, region, conf)
            if result and result.success:
                self.stats.ok_script_hits += 1
                self.stats.ok_script_time_total += result.time_ms
                self.stats.image_stats[img_name]['ok_script_hits'] += 1
                self.stats.image_stats[img_name]['ok_script_time'] += result.time_ms
                return result
        
        # ã€å„ªå…ˆç´š 2ã€‘pyautogui
        result = self._locate_with_pyautogui(image_path, region, conf)
        if result and result.success:
            self.stats.pyautogui_hits += 1
            self.stats.pyautogui_time_total += result.time_ms
            self.stats.image_stats[img_name]['pyautogui_hits'] += 1
            self.stats.image_stats[img_name]['pyautogui_time'] += result.time_ms
            return result
        
        return None
    
    def _locate_with_ok_script(
        self,
        image_path: str,
        region: Tuple[int, int, int, int] = None,
        confidence: float = 0.7  # é™ä½é»˜èªç½®ä¿¡åº¦ä»¥æé«˜å°ç•«é¢è®ŠåŒ–çš„å®¹éŒ¯æ€§
    ) -> Optional[RecognitionResult]:
        """
        ä½¿ç”¨ OK Script / OpenCV å®šä½åœ–ç‰‡
        """
        start_time = time.perf_counter()
        
        try:
            # å¦‚æœ OK Script å¯ç”¨
            if self._ok_script is not None:
                # ä½¿ç”¨ OK Script çš„ template matching
                loc = self._ok_script.find_template(image_path, confidence=confidence)
                if loc:
                    elapsed_ms = (time.perf_counter() - start_time) * 1000
                    # è®€å–æ¨¡æ¿å°ºå¯¸
                    try:
                        from PIL import Image
                        template_img = Image.open(image_path)
                        template_w, template_h = template_img.size
                    except:
                        template_w, template_h = 50, 50  # é è¨­å°ºå¯¸
                    
                    # ğŸ¯ OK Script çš„ find_template å¯èƒ½è¿”å›ä¸­å¿ƒé»æˆ–å·¦ä¸Šè§’
                    # æ ¹æ“š OK Script æ–‡æª”ï¼Œfind_template è¿”å›çš„æ˜¯ (x, y) åº§æ¨™
                    # ä½†éœ€è¦ç¢ºèªæ˜¯å·¦ä¸Šè§’é‚„æ˜¯ä¸­å¿ƒé»
                    # ç‚ºäº†å®‰å…¨èµ·è¦‹ï¼Œæˆ‘å€‘å‡è¨­è¿”å›çš„æ˜¯ä¸­å¿ƒé»ï¼Œéœ€è¦è½‰æ›ç‚ºå·¦ä¸Šè§’
                    ok_script_x = loc[0]
                    ok_script_y = loc[1]
                    
                    # ğŸ¯ å˜—è©¦å…©ç¨®æƒ…æ³ï¼š
                    # 1. å¦‚æœè¿”å›çš„æ˜¯ä¸­å¿ƒé»ï¼Œéœ€è¦æ¸›å»å¯¬é«˜çš„ä¸€åŠ
                    # 2. å¦‚æœè¿”å›çš„æ˜¯å·¦ä¸Šè§’ï¼Œç›´æ¥ä½¿ç”¨
                    # ç”±æ–¼ç„¡æ³•ç¢ºå®šï¼Œæˆ‘å€‘å…ˆå‡è¨­æ˜¯å·¦ä¸Šè§’ï¼ˆèˆ‡ OpenCV ä¸€è‡´ï¼‰
                    # å¦‚æœå¾ŒçºŒé©—è­‰ç™¼ç¾ä¸å°ï¼Œæœƒåœ¨ camera_page.py ä¸­é€²è¡Œèª¿æ•´
                    top_left_x = ok_script_x
                    top_left_y = ok_script_y
                    
                    return RecognitionResult(
                        success=True,
                        method='ok_script',
                        x=top_left_x,
                        y=top_left_y,
                        width=template_w,  # ä½¿ç”¨æ¨¡æ¿åœ–ç‰‡å¯¬åº¦
                        height=template_h,  # ä½¿ç”¨æ¨¡æ¿åœ–ç‰‡é«˜åº¦
                        confidence=confidence,
                        time_ms=elapsed_ms,
                        image_path=image_path
                    )
            
            # å›é€€åˆ° OpenCV template matching
            elif CV2_AVAILABLE:
                result = self._locate_with_opencv(image_path, region, confidence)
                if result:
                    result.method = 'ok_script'  # æ¨™è¨˜ç‚º ok_script åˆ†é¡çµ±è¨ˆ
                    return result
                    
        except Exception as e:
            if self.logger:
                self.logger.debug(f"OK Script è¾¨è­˜ç•°å¸¸: {e}")
        
        return None
    
    def _locate_with_opencv(
        self,
        image_path: str,
        region: Tuple[int, int, int, int] = None,
        confidence: float = 0.7  # é™ä½é»˜èªç½®ä¿¡åº¦ä»¥æé«˜å°ç•«é¢è®ŠåŒ–çš„å®¹éŒ¯æ€§
    ) -> Optional[RecognitionResult]:
        """
        ä½¿ç”¨ OpenCV template matching å®šä½åœ–ç‰‡
        é€™æ˜¯ OK Script çš„æ ¸å¿ƒæ¼”ç®—æ³•
        """
        if not CV2_AVAILABLE:
            return None
        
        start_time = time.perf_counter()
        
        try:
            # æˆªå–è¢å¹•
            if region:
                screenshot = pyautogui.screenshot(region=region)
                offset_x, offset_y = region[0], region[1]
            else:
                screenshot = pyautogui.screenshot()
                offset_x, offset_y = 0, 0
            
            # è½‰æ›ç‚º OpenCV æ ¼å¼
            screen_np = np.array(screenshot)
            screen_bgr = cv2.cvtColor(screen_np, cv2.COLOR_RGB2BGR)
            screen_gray = cv2.cvtColor(screen_bgr, cv2.COLOR_BGR2GRAY)
            
            # è®€å–æ¨¡æ¿
            template = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
            if template is None:
                return None
            
            # å¤šå°ºåº¦ template matching
            best_match = None
            best_confidence = 0
            
            # å˜—è©¦ä¸åŒç¸®æ”¾æ¯”ä¾‹
            scales = [1.0, 0.95, 1.05, 0.9, 1.1]
            
            for scale in scales:
                if scale != 1.0:
                    scaled_template = cv2.resize(
                        template,
                        None,
                        fx=scale,
                        fy=scale,
                        interpolation=cv2.INTER_AREA
                    )
                else:
                    scaled_template = template
                
                # ç¢ºä¿æ¨¡æ¿ä¸è¶…éè¢å¹•
                if scaled_template.shape[0] > screen_gray.shape[0] or \
                   scaled_template.shape[1] > screen_gray.shape[1]:
                    continue
                
                # Template matching
                result = cv2.matchTemplate(
                    screen_gray,
                    scaled_template,
                    cv2.TM_CCOEFF_NORMED
                )
                
                min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
                
                if max_val > best_confidence and max_val >= confidence:
                    best_confidence = max_val
                    # ğŸ¯ OpenCV matchTemplate è¿”å›çš„æ˜¯å·¦ä¸Šè§’åº§æ¨™ï¼Œä¸æ˜¯ä¸­å¿ƒé»
                    # max_loc[0], max_loc[1] å·²ç¶“æ˜¯å·¦ä¸Šè§’ï¼ŒåŠ ä¸Š offset å³å¯
                    top_left_x = max_loc[0] + offset_x
                    top_left_y = max_loc[1] + offset_y
                    best_match = (top_left_x, top_left_y, max_val)
            
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            
            if best_match:
                # è®€å–æ¨¡æ¿å°ºå¯¸ï¼ˆä½¿ç”¨æœ€å¾ŒåŒ¹é…çš„æ¨¡æ¿ï¼‰
                template = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
                template_h, template_w = template.shape if template is not None else (50, 50)
                return RecognitionResult(
                    success=True,
                    method='opencv',
                    x=best_match[0],
                    y=best_match[1],
                    width=template_w,
                    height=template_h,
                    confidence=best_match[2],
                    time_ms=elapsed_ms,
                    image_path=image_path
                )
                
        except Exception as e:
            if self.logger:
                self.logger.debug(f"OpenCV è¾¨è­˜ç•°å¸¸: {e}")
        
        return None
    
    def _locate_with_pyautogui(
        self,
        image_path: str,
        region: Tuple[int, int, int, int] = None,
        confidence: float = 0.7  # é™ä½é»˜èªç½®ä¿¡åº¦ä»¥æé«˜å°ç•«é¢è®ŠåŒ–çš„å®¹éŒ¯æ€§
    ) -> Optional[RecognitionResult]:
        """
        ä½¿ç”¨ pyautogui å®šä½åœ–ç‰‡ï¼ˆåŸæœ‰æ–¹æ³•ï¼‰
        """
        start_time = time.perf_counter()
        
        try:
            loc = pyautogui.locateOnScreen(
                image_path,
                confidence=confidence,
                region=region
            )
            
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            
            if loc:
                center = pyautogui.center(loc)
                return RecognitionResult(
                    success=True,
                    method='pyautogui',
                    x=center.x,
                    y=center.y,
                    width=loc.width,  # ä½¿ç”¨å¯¦éš›è¾¨è­˜åˆ°çš„ç‰©ä»¶å¯¬åº¦
                    height=loc.height,  # ä½¿ç”¨å¯¦éš›è¾¨è­˜åˆ°çš„ç‰©ä»¶é«˜åº¦
                    confidence=confidence,
                    time_ms=elapsed_ms,
                    image_path=image_path
                )
                
        except Exception as e:
            if self.logger:
                self.logger.debug(f"pyautogui è¾¨è­˜ç•°å¸¸: {e}")
        
        return None
    
    def record_ocr_hit(self, time_ms: float):
        """è¨˜éŒ„ OCR å‘½ä¸­"""
        self.stats.ocr_hits += 1
        self.stats.ocr_time_total += time_ms
    
    def record_vlm_hit(self, time_ms: float):
        """è¨˜éŒ„ VLM å‘½ä¸­"""
        self.stats.vlm_hits += 1
        self.stats.vlm_time_total += time_ms
    
    def record_coordinate_hit(self):
        """è¨˜éŒ„åº§æ¨™ä¿åº•å‘½ä¸­"""
        self.stats.coordinate_hits += 1
        # å¢åŠ é€£çºŒåœ–åƒè¾¨è­˜å¤±æ•—è¨ˆæ•¸
        self._consecutive_image_recognition_failures += 1
    
    def record_image_recognition_success(self):
        """è¨˜éŒ„åœ–åƒè¾¨è­˜æˆåŠŸï¼ˆé‡ç½®é€£çºŒå¤±æ•—è¨ˆæ•¸ï¼‰"""
        self._consecutive_image_recognition_failures = 0
    
    def get_consecutive_image_recognition_failures(self) -> int:
        """å–å¾—é€£çºŒåœ–åƒè¾¨è­˜å¤±æ•—æ¬¡æ•¸"""
        return self._consecutive_image_recognition_failures
    
    def reset_consecutive_failures(self):
        """é‡ç½®é€£çºŒå¤±æ•—è¨ˆæ•¸ï¼ˆç”¨æ–¼æ–°çš„æ¸¬è©¦é–‹å§‹ï¼‰"""
        self._consecutive_image_recognition_failures = 0
    
    def get_stats_summary(self) -> str:
        """
        å–å¾—çµ±è¨ˆæ‘˜è¦
        """
        # è¨ˆç®— OCR å’Œ VLM çš„å‘½ä¸­ç‡
        ocr_rate = (self.stats.ocr_hits / self.stats.total_attempts * 100) if self.stats.total_attempts > 0 else 0
        vlm_rate = self.stats.get_vlm_hit_rate()
        coord_rate = (self.stats.coordinate_hits / self.stats.total_attempts * 100) if self.stats.total_attempts > 0 else 0
        
        lines = [
            "=" * 60,
            "[STATS] Image Recognition Statistics Report",
            "=" * 60,
            f"Total Attempts: {self.stats.total_attempts}",
            "",
            "[Hit Rate]",
            f"  OK Script/OpenCV: {self.stats.ok_script_hits}/{self.stats.total_attempts} ({self.stats.get_ok_script_hit_rate():.1f}%)",
            f"  VLM (LLM Vision): {self.stats.vlm_hits}/{self.stats.total_attempts} ({vlm_rate:.1f}%)",
            f"  pyautogui:        {self.stats.pyautogui_hits}/{self.stats.total_attempts} ({self.stats.get_pyautogui_hit_rate():.1f}%)",
            f"  OCR:              {self.stats.ocr_hits}/{self.stats.total_attempts} ({ocr_rate:.1f}%)",
            f"  Coordinate:       {self.stats.coordinate_hits}/{self.stats.total_attempts} ({coord_rate:.1f}%)",
            "",
            "[Average Recognition Time]",
            f"  OK Script/OpenCV: {self.stats.get_ok_script_avg_time():.2f} ms",
            f"  VLM (LLM Vision): {self.stats.get_vlm_avg_time():.2f} ms",
            f"  pyautogui:        {self.stats.get_pyautogui_avg_time():.2f} ms",
            "",
            "[Per-Image Statistics]",
        ]
        
        for img_name, stats in sorted(self.stats.image_stats.items()):
            attempts = stats['attempts']
            ok_hits = stats['ok_script_hits']
            py_hits = stats['pyautogui_hits']
            ok_rate = (ok_hits / attempts * 100) if attempts > 0 else 0
            py_rate = (py_hits / attempts * 100) if attempts > 0 else 0
            lines.append(f"  {img_name}:")
            lines.append(f"    Attempts: {attempts}, OK Script: {ok_hits} ({ok_rate:.0f}%), pyautogui: {py_hits} ({py_rate:.0f}%)")
        
        if not self.stats.image_stats:
            lines.append("  (No image data yet)")
        
        lines.append("=" * 60)
        
        return "\n".join(lines)
    
    def save_stats(self):
        """ä¿å­˜çµ±è¨ˆåˆ°æ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(self._stats_file), exist_ok=True)
            
            data = {
                'timestamp': datetime.now().isoformat(),
                'total_attempts': self.stats.total_attempts,
                'ok_script_hits': self.stats.ok_script_hits,
                'ok_script_time_total': self.stats.ok_script_time_total,
                'pyautogui_hits': self.stats.pyautogui_hits,
                'pyautogui_time_total': self.stats.pyautogui_time_total,
                'ocr_hits': self.stats.ocr_hits,
                'ocr_time_total': self.stats.ocr_time_total,
                'vlm_hits': self.stats.vlm_hits,
                'vlm_time_total': self.stats.vlm_time_total,
                'coordinate_hits': self.stats.coordinate_hits,
                'image_stats': self.stats.image_stats
            }
            
            with open(self._stats_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            if self.logger:
                self.logger.warning(f"ä¿å­˜çµ±è¨ˆå¤±æ•—: {e}")
    
    def _load_stats(self):
        """è¼‰å…¥æ­·å²çµ±è¨ˆ"""
        try:
            if os.path.exists(self._stats_file):
                with open(self._stats_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                self.stats.total_attempts = data.get('total_attempts', 0)
                self.stats.ok_script_hits = data.get('ok_script_hits', 0)
                self.stats.ok_script_time_total = data.get('ok_script_time_total', 0.0)
                self.stats.pyautogui_hits = data.get('pyautogui_hits', 0)
                self.stats.pyautogui_time_total = data.get('pyautogui_time_total', 0.0)
                self.stats.ocr_hits = data.get('ocr_hits', 0)
                self.stats.ocr_time_total = data.get('ocr_time_total', 0.0)
                self.stats.vlm_hits = data.get('vlm_hits', 0)
                self.stats.vlm_time_total = data.get('vlm_time_total', 0.0)
                self.stats.coordinate_hits = data.get('coordinate_hits', 0)
                self.stats.image_stats = data.get('image_stats', {})
                
        except Exception:
            pass  # å¿½ç•¥è¼‰å…¥éŒ¯èª¤ï¼Œä½¿ç”¨é è¨­å€¼
    
    def reset_stats(self):
        """é‡ç½®çµ±è¨ˆ"""
        self.stats = RecognitionStats()
        if os.path.exists(self._stats_file):
            os.remove(self._stats_file)


# å…¨åŸŸå–®ä¾‹
_recognizer = None

def get_recognizer() -> OKScriptRecognizer:
    """å–å¾—å…¨åŸŸè¾¨è­˜å™¨å¯¦ä¾‹"""
    global _recognizer
    if _recognizer is None:
        _recognizer = OKScriptRecognizer()
    return _recognizer
