# -*- coding: utf-8 -*-
"""
VLM (Vision Language Model) åœ–åƒè¾¨è­˜æ¨¡çµ„

æ”¯æ´å¤šç¨® VLM å¾Œç«¯ï¼š
1. OpenAI GPT-4V (API)
2. Claude Vision (API)
3. Qwen-VL (æœ¬åœ°/API)
4. LLaVA (æœ¬åœ°)
5. Ollama (æœ¬åœ°ï¼Œæ”¯æ´ llava, bakllava ç­‰)

å„ªé»ï¼š
- æ›´æ™ºèƒ½çš„ UI å…ƒç´ è­˜åˆ¥
- æ”¯æ´è‡ªç„¶èªè¨€æŸ¥è©¢ï¼ˆå¦‚ "æ‰¾åˆ°ç¢ºèªæŒ‰éˆ•"ï¼‰
- æ›´å¥½çš„ä¸Šä¸‹æ–‡ç†è§£
"""

import os
import time
import base64
from typing import Optional, Tuple, Dict, Any
from dataclasses import dataclass
from io import BytesIO

import pyautogui
from PIL import Image

# å˜—è©¦å°å…¥å„ç¨® VLM å®¢æˆ¶ç«¯
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    import ollama
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False


@dataclass
class VLMResult:
    """VLM è¾¨è­˜çµæœ"""
    success: bool
    x: int = 0
    y: int = 0
    confidence: float = 0.0
    time_ms: float = 0.0
    description: str = ""
    raw_response: str = ""
    box: Tuple[int, int, int, int] = None  # é‚Šç•Œæ¡† (xmin, ymin, xmax, ymax)


class VLMRecognizer:
    """
    VLM è¦–è¦ºèªè¨€æ¨¡å‹è¾¨è­˜å™¨
    
    ä½¿ç”¨ VLM ä¾†ç†è§£è¢å¹•æˆªåœ–ä¸¦å®šä½ UI å…ƒç´ 
    """
    
    def __init__(self, backend: str = "ollama", model: str = None):
        """
        åˆå§‹åŒ– VLM è¾¨è­˜å™¨
        
        Args:
            backend: å¾Œç«¯é¡å‹ ('openai', 'anthropic', 'ollama', 'qwen')
            model: æ¨¡å‹åç¨±ï¼ˆå¦‚ 'gpt-4-vision-preview', 'llava'ï¼‰
        """
        self.backend = backend
        self.model = model or self._get_default_model(backend)
        self.logger = None
        self._client = None
        self._initialized = False
        
        # çµ±è¨ˆ
        self.stats = {
            'attempts': 0,
            'hits': 0,
            'total_time': 0.0
        }
    
    def _get_default_model(self, backend: str) -> str:
        """å–å¾—é è¨­æ¨¡å‹åç¨±"""
        defaults = {
            'openai': 'gpt-4o',  # GPT-4o æ”¯æ´è¦–è¦º
            'anthropic': 'claude-3-5-sonnet-20241022',
            'ollama': 'llava',  # æœ¬åœ° LLaVA
            'qwen': 'qwen-vl-plus'
        }
        return defaults.get(backend, 'llava')
    
    def set_logger(self, logger):
        """è¨­ç½®æ—¥èªŒè¨˜éŒ„å™¨"""
        self.logger = logger
    
    def _log(self, level: str, msg: str):
        """è¨˜éŒ„æ—¥èªŒï¼ˆè‡ªå‹•æ¸…ç† emoji é¿å…ç·¨ç¢¼éŒ¯èª¤ï¼‰"""
        # æ¸…ç† emoji é¿å… cp950 ç·¨ç¢¼éŒ¯èª¤
        safe_msg = msg.replace("ğŸ”", "[DEBUG]").replace("ğŸ¤–", "[VLM]").replace("ğŸ“", "[OCR]").replace("ğŸ¯", "[OK]").replace("ğŸ“¸", "[IMG]").replace("ğŸ“Š", "[STAT]").replace("âŒ", "[ERROR]").replace("âœ…", "[OK]").replace("âš ï¸", "[WARN]").replace("â³", "[WAIT]").replace("ğŸš€", "[START]").replace("ğŸ’¡", "[TIP]")
        if self.logger:
            getattr(self.logger, level)(safe_msg)
        else:
            print(f"[{level.upper()}] {safe_msg}")
    
    def _init_client(self):
        """å»¶é²åˆå§‹åŒ–å®¢æˆ¶ç«¯"""
        if self._initialized:
            return
        
        try:
            if self.backend == 'openai':
                if not OPENAI_AVAILABLE:
                    raise ImportError("openai package not installed")
                self._client = openai.OpenAI()
                
            elif self.backend == 'anthropic':
                if not ANTHROPIC_AVAILABLE:
                    raise ImportError("anthropic package not installed")
                self._client = anthropic.Anthropic()
                
            elif self.backend == 'ollama':
                if not OLLAMA_AVAILABLE:
                    raise ImportError("ollama package not installed")
                # Ollama ä½¿ç”¨å‡½æ•¸èª¿ç”¨ï¼Œä¸éœ€è¦å®¢æˆ¶ç«¯å¯¦ä¾‹
                self._client = True
                
            self._initialized = True
            self._log('info', f"âœ… VLM åˆå§‹åŒ–æˆåŠŸ: {self.backend}/{self.model}")
            
        except Exception as e:
            self._log('warning', f"âš ï¸ VLM åˆå§‹åŒ–å¤±æ•—: {e}")
            self._client = None
    
    def _screenshot_to_base64(self, region: Tuple[int, int, int, int] = None) -> tuple:
        """
        æˆªåœ–ä¸¦è½‰æ›ç‚º base64
        
        Returns:
            (base64_string, original_size, resized_size)
            original_size: (width, height) åŸå§‹æˆªåœ–å°ºå¯¸
            resized_size: (width, height) ç¸®å°å¾Œçš„æˆªåœ–å°ºå¯¸
        """
        if region:
            screenshot = pyautogui.screenshot(region=region)
            original_size = (region[2], region[3])  # (width, height)
        else:
            screenshot = pyautogui.screenshot()
            original_size = screenshot.size  # (width, height)
        
        # ç¸®å°åœ–ç‰‡ä»¥æ¸›å°‘ API æˆæœ¬å’Œå»¶é²
        max_size = (1280, 720)
        resized_size = screenshot.size  # è¨˜éŒ„ç¸®å°å‰çš„å°ºå¯¸
        screenshot.thumbnail(max_size, Image.Resampling.LANCZOS)
        resized_size = screenshot.size  # è¨˜éŒ„ç¸®å°å¾Œçš„å°ºå¯¸
        
        buffer = BytesIO()
        screenshot.save(buffer, format='PNG')
        base64_str = base64.b64encode(buffer.getvalue()).decode('utf-8')
        
        return base64_str, original_size, resized_size
    
    def find_element(
        self,
        query: str,
        region: Tuple[int, int, int, int] = None,
        screenshot: Image.Image = None
    ) -> Optional[VLMResult]:
        """
        ä½¿ç”¨ VLM åœ¨è¢å¹•ä¸Šå°‹æ‰¾å…ƒç´ 
        
        Args:
            query: è‡ªç„¶èªè¨€æè¿°ï¼ˆå¦‚ "ç«™é»ç®¡ç† æŒ‰éˆ•" æˆ– "è—è‰²çš„ç¢ºèªæŒ‰éˆ•"ï¼‰
            region: æœå°‹å€åŸŸ (left, top, width, height)
            screenshot: å¯é¸çš„ PIL Imageï¼ˆä¸æä¾›å‰‡è‡ªå‹•æˆªåœ–ï¼‰
            
        Returns:
            VLMResult æˆ– None
        """
        self._init_client()
        
        if not self._client:
            return None
        
        self.stats['attempts'] += 1
        start_time = time.perf_counter()
        
        try:
            # æº–å‚™æˆªåœ–
            original_size = None
            resized_size = None
            
            if screenshot:
                buffer = BytesIO()
                screenshot.save(buffer, format='PNG')
                img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
                original_size = screenshot.size
                resized_size = screenshot.size  # å¦‚æœæ²’æœ‰ç¸®å°ï¼Œå°ºå¯¸ç›¸åŒ
            else:
                img_base64, original_size, resized_size = self._screenshot_to_base64(region)
            
            # æ§‹å»ºæç¤ºè©
            prompt = self._build_prompt(query, region)
            
            # èª¿ç”¨ VLM
            if self.backend == 'openai':
                result = self._call_openai(img_base64, prompt)
            elif self.backend == 'anthropic':
                result = self._call_anthropic(img_base64, prompt)
            elif self.backend == 'ollama':
                result = self._call_ollama(img_base64, prompt)
            else:
                return None
            
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            
            if result:
                result.time_ms = elapsed_ms
                if result.success:
                    self.stats['hits'] += 1
                    self.stats['total_time'] += elapsed_ms
                    
                    # ========================================================================
                    # ğŸ¯ åº§æ¨™æ›ç®—é‚è¼¯ï¼ˆæ ¸å¿ƒé‚è¼¯ï¼Œè«‹å‹¿éš¨æ„ä¿®æ”¹ï¼‰
                    # ========================================================================
                    # 
                    # åº§æ¨™æ›ç®—æµç¨‹ï¼š
                    # 1. VLM è¿”å›çš„åº§æ¨™æ˜¯ç›¸å°æ–¼ç¸®å°å¾Œçš„æˆªåœ–ï¼ˆå¦‚æœæˆªåœ–è¢«ç¸®å°ï¼‰
                    # 2. å…ˆå°‡åº§æ¨™è½‰æ›å›åŸå§‹æˆªåœ–å°ºå¯¸
                    # 3. å¦‚æœæä¾›äº† regionï¼Œå†åŠ ä¸Š region çš„å·¦ä¸Šè§’åç§»ï¼Œå¾—åˆ°å±å¹•çµ•å°åº§æ¨™
                    #
                    # é‡è¦ï¼šæ­¤é‚è¼¯å½±éŸ¿æ‰€æœ‰ä½¿ç”¨ VLM çš„åœ°æ–¹ï¼Œä¿®æ”¹å‰è«‹ï¼š
                    # 1. é‹è¡Œ test_vlm_coordinate_conversion.py é©—è­‰
                    # 2. æª¢æŸ¥æ‰€æœ‰ä½¿ç”¨ VLM çš„åœ°æ–¹æ˜¯å¦ä»ç„¶æ­£å¸¸å·¥ä½œ
                    # 3. ç¢ºä¿åº§æ¨™æ›ç®—é‚è¼¯çš„æ­£ç¢ºæ€§å’Œç©©å®šæ€§
                    #
                    # ========================================================================
                    
                    if original_size and resized_size:
                        # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
                        scale_x = original_size[0] / resized_size[0] if resized_size[0] > 0 else 1.0
                        scale_y = original_size[1] / resized_size[1] if resized_size[1] > 0 else 1.0
                        
                        # ğŸ¯ VLM è¿”å›çš„åº§æ¨™å¯èƒ½æ˜¯æ¯”ä¾‹åº§æ¨™ï¼ˆ0-1ï¼‰æˆ–åƒç´ åº§æ¨™
                        # åˆ¤æ–·æ¨™æº–ï¼šå¦‚æœåº§æ¨™å€¼ < 1.0ï¼Œèªç‚ºæ˜¯æ¯”ä¾‹åº§æ¨™ï¼›å¦å‰‡æ˜¯åƒç´ åº§æ¨™
                        # æ³¨æ„ï¼šresult.x å’Œ result.y åœ¨ _parse_response ä¸­å·²ç¶“æ˜¯ float
                        is_ratio_coord = (0.0 < abs(result.x) < 1.0) or (0.0 < abs(result.y) < 1.0)
                        
                        if is_ratio_coord:
                            # æ¯”ä¾‹åº§æ¨™ï¼šå…ˆè½‰æ›ç‚ºç¸®å°å¾Œåœ–ç‰‡çš„åƒç´ åº§æ¨™
                            pixel_x = result.x * resized_size[0]
                            pixel_y = result.y * resized_size[1]
                            self._log('debug', f"æ¯”ä¾‹åº§æ¨™è½‰æ›: VLMè¿”å›æ¯”ä¾‹=({result.x:.3f}, {result.y:.3f}), ç¸®å°å¾Œåœ–ç‰‡åƒç´ =({pixel_x:.1f}, {pixel_y:.1f})")
                        else:
                            # åƒç´ åº§æ¨™ï¼šç›´æ¥ä½¿ç”¨ï¼ˆå‡è¨­æ˜¯ç›¸å°æ–¼ç¸®å°å¾Œçš„åœ–ç‰‡ï¼‰
                            pixel_x = result.x
                            pixel_y = result.y
                            self._log('debug', f"åƒç´ åº§æ¨™: VLMè¿”å›=({pixel_x:.1f}, {pixel_y:.1f})")
                        
                        # ğŸ¯ å°‡åº§æ¨™ï¼ˆç›¸å°æ–¼ç¸®å°å¾Œçš„åœ–ç‰‡ï¼‰è½‰æ›å›åŸå§‹æˆªåœ–å°ºå¯¸
                        # æ³¨æ„ï¼šoriginal_size æ˜¯ region çš„å°ºå¯¸ï¼ˆå¦‚æœæä¾›äº† regionï¼‰ï¼Œå¦å‰‡æ˜¯å…¨å±å°ºå¯¸
                        result.x = int(pixel_x * scale_x)
                        result.y = int(pixel_y * scale_y)
                        
                        self._log('debug', f"åº§æ¨™è½‰æ›: åŸå§‹å°ºå¯¸={original_size}, ç¸®å°å¾Œ={resized_size}, ç¸®æ”¾æ¯”ä¾‹=({scale_x:.3f}, {scale_y:.3f}), è½‰æ›å¾Œ=({result.x}, {result.y})")
                        
                        # ğŸ¯ é©—è­‰è½‰æ›å¾Œçš„åº§æ¨™æ˜¯å¦åœ¨åŸå§‹æˆªåœ–ç¯„åœå…§
                        if result.x < 0 or result.x > original_size[0] or result.y < 0 or result.y > original_size[1]:
                            self._log('warning', f"åº§æ¨™è½‰æ›å¾Œè¶…å‡ºåŸå§‹æˆªåœ–ç¯„åœ: ({result.x}, {result.y}), åŸå§‹æˆªåœ–å°ºå¯¸={original_size}")
                        
                        # ğŸ¯ è™•ç†é‚Šç•Œæ¡†ï¼ˆboxï¼‰çš„åº§æ¨™è½‰æ›ï¼ˆåœ¨ region è™•ç†ä¹‹å‰ï¼‰
                        if result.box:
                            box_xmin, box_ymin, box_xmax, box_ymax = result.box
                            
                            # åˆ¤æ–· box æ˜¯å¦ç‚ºæ¯”ä¾‹åº§æ¨™
                            is_box_ratio = (0.0 < abs(box_xmin) < 1.0) or (0.0 < abs(box_ymin) < 1.0)
                            
                            if is_box_ratio:
                                # æ¯”ä¾‹åº§æ¨™ï¼šè½‰æ›ç‚ºç¸®å°å¾Œåœ–ç‰‡çš„åƒç´ åº§æ¨™
                                box_xmin = box_xmin * resized_size[0]
                                box_ymin = box_ymin * resized_size[1]
                                box_xmax = box_xmax * resized_size[0]
                                box_ymax = box_ymax * resized_size[1]
                            
                            # è½‰æ›å›åŸå§‹æˆªåœ–å°ºå¯¸
                            box_xmin = int(box_xmin * scale_x)
                            box_ymin = int(box_ymin * scale_y)
                            box_xmax = int(box_xmax * scale_x)
                            box_ymax = int(box_ymax * scale_y)
                            
                            # æš«æ™‚ä¿å­˜è½‰æ›å¾Œçš„ boxï¼ˆé‚„æœªåŠ  region åç§»ï¼‰
                            result.box = (int(box_xmin), int(box_ymin), int(box_xmax), int(box_ymax))
                            self._log('debug', f"é‚Šç•Œæ¡†è½‰æ›ï¼ˆè½‰æ›å¾Œï¼‰: box=({box_xmin}, {box_ymin}, {box_xmax}, {box_ymax})")
                    else:
                        # å¦‚æœæ²’æœ‰ original_size/resized_sizeï¼Œbox ä¿æŒåŸæ¨£ï¼ˆå‡è¨­å·²ç¶“æ˜¯åƒç´ åº§æ¨™ï¼‰
                        if result.box:
                            self._log('debug', f"é‚Šç•Œæ¡†æœªè½‰æ›ï¼ˆç„¡ç¸®æ”¾ä¿¡æ¯ï¼‰: box={result.box}")
                    
                    # ğŸ¯ åŠ ä¸Š region åç§»ï¼ˆå¦‚æœæœ‰ï¼‰
                    # æ³¨æ„ï¼šå¦‚æœæä¾›äº† regionï¼ŒVLM è¿”å›çš„åº§æ¨™æ˜¯ç›¸å°æ–¼ region æˆªåœ–çš„
                    # æˆ‘å€‘éœ€è¦åŠ ä¸Š region çš„å·¦ä¸Šè§’åº§æ¨™æ‰èƒ½å¾—åˆ°å±å¹•çµ•å°åº§æ¨™
                    if region:
                        region_left = region[0]
                        region_top = region[1]
                        region_width = region[2]
                        region_height = region[3]
                        
                        # ğŸ¯ é©—è­‰åº§æ¨™æ˜¯å¦åœ¨ region ç¯„åœå…§ï¼ˆè½‰æ›å¾Œï¼ŒåŠ åç§»å‰ï¼‰
                        # æ­¤æ™‚ result.x, result.y æ‡‰è©²æ˜¯ç›¸å°æ–¼ region æˆªåœ–çš„åº§æ¨™
                        coord_before_offset_x = result.x
                        coord_before_offset_y = result.y
                        
                        # å¦‚æœåº§æ¨™è¶…å‡º region ç¯„åœï¼Œè¨˜éŒ„è­¦å‘Š
                        if coord_before_offset_x < 0 or coord_before_offset_x > region_width or \
                           coord_before_offset_y < 0 or coord_before_offset_y > region_height:
                            self._log('warning', f"VLM è¿”å›åº§æ¨™è¶…å‡º region ç¯„åœ: ({coord_before_offset_x:.1f}, {coord_before_offset_y:.1f}), region å°ºå¯¸=({region_width}, {region_height})")
                            # å¦‚æœ y åº§æ¨™æ˜é¡¯è¶…å‡ºç¯„åœï¼ˆè¶…é 50pxï¼‰ï¼Œå¯èƒ½æ˜¯ VLM è¿”å›äº†ç›¸å°æ–¼å…¨å±çš„åº§æ¨™ï¼Œæ‹’çµ•æ­¤çµæœ
                            if coord_before_offset_y > region_height + 50:
                                self._log('warning', f"æª¢æ¸¬åˆ° y åº§æ¨™æ˜é¡¯è¶…å‡º region é«˜åº¦ï¼ˆè¶…é 50pxï¼‰ï¼Œå¯èƒ½æ˜¯ VLM è¿”å›äº†ç›¸å°æ–¼å…¨å±çš„åº§æ¨™ï¼Œå°‡æ‹’çµ•æ­¤çµæœ")
                                result.success = False
                                return result
                            # å¦‚æœ x åº§æ¨™æ˜é¡¯è¶…å‡ºç¯„åœï¼ˆè¶…é 50pxï¼‰ï¼Œä¹Ÿå¯èƒ½æ˜¯ VLM è¿”å›äº†éŒ¯èª¤çš„åº§æ¨™ï¼Œæ‹’çµ•æ­¤çµæœ
                            if coord_before_offset_x > region_width + 50:
                                self._log('warning', f"æª¢æ¸¬åˆ° x åº§æ¨™æ˜é¡¯è¶…å‡º region å¯¬åº¦ï¼ˆè¶…é 50pxï¼‰ï¼Œå¯èƒ½æ˜¯ VLM è¿”å›äº†éŒ¯èª¤çš„åº§æ¨™ï¼Œå°‡æ‹’çµ•æ­¤çµæœ")
                                result.success = False
                                return result
                        
                        # ğŸ¯ åŠ ä¸Š region åç§»ï¼Œå¾—åˆ°å±å¹•çµ•å°åº§æ¨™
                        result.x += region_left
                        result.y += region_top
                        self._log('debug', f"åŠ ä¸Š region åç§»: region=({region_left}, {region_top}), è½‰æ›å‰=({coord_before_offset_x:.1f}, {coord_before_offset_y:.1f}), æœ€çµ‚åº§æ¨™=({result.x}, {result.y})")
                        
                        # ğŸ¯ ç‚ºé‚Šç•Œæ¡†ï¼ˆboxï¼‰åŠ ä¸Š region åç§»
                        if result.box:
                            box_xmin, box_ymin, box_xmax, box_ymax = result.box
                            box_xmin += region_left
                            box_ymin += region_top
                            box_xmax += region_left
                            box_ymax += region_top
                            result.box = (int(box_xmin), int(box_ymin), int(box_xmax), int(box_ymax))
                            self._log('debug', f"é‚Šç•Œæ¡†åŠ ä¸Š region åç§»: æœ€çµ‚ box=({box_xmin}, {box_ymin}, {box_xmax}, {box_ymax})")
                
                return result
                
        except Exception as e:
            self._log('warning', f"âš ï¸ VLM è¾¨è­˜ç•°å¸¸: {e}")
        
        return None
    
    def _build_prompt(self, query: str, region: Tuple = None) -> str:
        """æ§‹å»º VLM æç¤ºè©"""
        # å¦‚æœæœ‰ regionï¼Œåœ¨ prompt ä¸­æ˜ç¢ºèªªæ˜é€™æ˜¯æˆªåœ–çš„ä¸€éƒ¨åˆ†
        region_info = ""
        if region:
            region_info = f"\né‡è¦ï¼šé€™æ˜¯ä¸€å¼µå±€éƒ¨æˆªåœ–ï¼ŒåªåŒ…å«è¢å¹•çš„ä¸€éƒ¨åˆ†å€åŸŸã€‚æˆªåœ–çš„å°ºå¯¸æ˜¯ {region[2]}x{region[3]} åƒç´ ã€‚"
        
        # ğŸ¯ å„ªåŒ–æç¤ºè©ï¼šå°æ–¼éƒµç®±åœ°å€ï¼Œæä¾›æ›´æ˜ç¢ºçš„æŒ‡å¼•
        enhanced_query = query
        if "@" in query and "gmail" in query.lower():
            enhanced_query = f"æ‰¾åˆ°éƒµç®±åœ°å€æ–‡å­— '{query}'ï¼ˆé€šå¸¸å‰é¢æœ‰ä¸€å€‹é›²åœ–æ¨™æˆ–åœ–æ¨™ï¼Œæ–‡å­—å¯èƒ½æ˜¯ç™½è‰²æˆ–ç°è‰²ï¼‰"
        
        return f"""ä½ æ˜¯ä¸€å€‹ UI è‡ªå‹•åŒ–åŠ©æ‰‹ã€‚è«‹åˆ†æé€™å¼µè¢å¹•æˆªåœ–ï¼Œæ‰¾åˆ°ä»¥ä¸‹å…ƒç´ ï¼š

ç›®æ¨™å…ƒç´ ï¼š{enhanced_query}
{region_info}

é‡è¦æç¤ºï¼š
1. å¦‚æœç›®æ¨™æ˜¯éƒµç®±åœ°å€ï¼Œè«‹æ‰¾åˆ°å®Œæ•´çš„éƒµç®±æ–‡å­—ï¼ˆåŒ…æ‹¬ @ ç¬¦è™Ÿå’ŒåŸŸåï¼‰
2. å¦‚æœç›®æ¨™æ˜¯æŒ‰éˆ•æˆ–é¸å–®é …ï¼Œè«‹æ‰¾åˆ°å¯é»æ“Šçš„å…ƒç´ ä¸­å¿ƒé»
3. åº§æ¨™å¿…é ˆæ˜¯ç›¸å°æ–¼æˆªåœ–çš„åƒç´ åº§æ¨™ï¼ˆä¸æ˜¯æ¯”ä¾‹åº§æ¨™ï¼‰
4. å¦‚æœæ‰¾ä¸åˆ°å…ƒç´ ï¼Œè«‹è¨­ç½® "found": false

è«‹å›è¦†ä»¥ä¸‹ JSON æ ¼å¼ï¼ˆåªå›è¦† JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼‰ï¼š
{{
    "found": true/false,
    "x": å…ƒç´ ä¸­å¿ƒé» X åº§æ¨™ï¼ˆåƒç´ ï¼Œç›¸å°æ–¼æˆªåœ–ï¼‰ï¼Œ
    "y": å…ƒç´ ä¸­å¿ƒé» Y åº§æ¨™ï¼ˆåƒç´ ï¼Œç›¸å°æ–¼æˆªåœ–ï¼‰ï¼Œ
    "confidence": ä¿¡å¿ƒåº¦ (0.0-1.0),
    "description": "å…ƒç´ æè¿°",
    "box": [xmin, ymin, xmax, ymax]
}}

å¦‚æœæ‰¾ä¸åˆ°ç›®æ¨™å…ƒç´ ï¼Œå›è¦†ï¼š
{{
    "found": false,
    "x": 0,
    "y": 0,
    "confidence": 0,
    "description": "æ‰¾ä¸åˆ°ç›®æ¨™å…ƒç´ çš„åŸå› ",
    "box": null
}}

å¦‚æœæ‰¾ä¸åˆ°ç›®æ¨™å…ƒç´ ï¼Œå›è¦†ï¼š
{{
    "found": false,
    "x": 0,
    "y": 0,
    "confidence": 0,
    "description": "æ‰¾ä¸åˆ°ç›®æ¨™å…ƒç´ çš„åŸå› ",
    "box": null
}}

é‡è¦è¦å‰‡ï¼š
1. åº§æ¨™å¿…é ˆæ˜¯ç›¸å°æ–¼é€™å¼µæˆªåœ–å·¦ä¸Šè§’ (0, 0) çš„åƒç´ åº§æ¨™
2. X åº§æ¨™ç¯„åœï¼š0 åˆ° {region[2] if region else "åœ–ç‰‡å¯¬åº¦"}
3. Y åº§æ¨™ç¯„åœï¼š0 åˆ° {region[3] if region else "åœ–ç‰‡é«˜åº¦"}
4. è«‹æº–ç¢ºå®šä½å…ƒç´ çš„ä¸­å¿ƒé»
5. å¦‚æœä½¿ç”¨æ¯”ä¾‹åº§æ¨™ï¼ˆ0.0-1.0ï¼‰ï¼Œè«‹ç¢ºä¿è½‰æ›ç‚ºåƒç´ åº§æ¨™å¾Œåœ¨ç¯„åœå…§
6. å¦‚æœæœ‰å¤šå€‹åŒ¹é…é …ï¼Œé¸æ“‡æœ€å¯èƒ½çš„ä¸€å€‹"""
    
    def _call_openai(self, img_base64: str, prompt: str) -> Optional[VLMResult]:
        """èª¿ç”¨ OpenAI GPT-4V"""
        try:
            response = self._client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{img_base64}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=500
            )
            
            return self._parse_response(response.choices[0].message.content)
            
        except Exception as e:
            self._log('warning', f"OpenAI API éŒ¯èª¤: {e}")
            return None
    
    def _call_anthropic(self, img_base64: str, prompt: str) -> Optional[VLMResult]:
        """èª¿ç”¨ Anthropic Claude"""
        try:
            response = self._client.messages.create(
                model=self.model,
                max_tokens=500,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image",
                                "source": {
                                    "type": "base64",
                                    "media_type": "image/png",
                                    "data": img_base64
                                }
                            },
                            {"type": "text", "text": prompt}
                        ]
                    }
                ]
            )
            
            return self._parse_response(response.content[0].text)
            
        except Exception as e:
            self._log('warning', f"Anthropic API éŒ¯èª¤: {e}")
            return None
    
    def _call_ollama(self, img_base64: str, prompt: str) -> Optional[VLMResult]:
        """èª¿ç”¨æœ¬åœ° Ollama (LLaVA ç­‰)"""
        try:
            response = ollama.chat(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": prompt,
                        "images": [img_base64]
                    }
                ]
            )
            
            return self._parse_response(response['message']['content'])
            
        except Exception as e:
            self._log('warning', f"Ollama éŒ¯èª¤: {e}")
            return None
    
    def _parse_response(self, response: str) -> Optional[VLMResult]:
        """è§£æ VLM å›æ‡‰"""
        import json
        import re
        
        try:
            # å˜—è©¦æå– JSONï¼ˆæ”¯æŒå¤šå±¤åµŒå¥—çš„ JSON æˆ– code blockï¼‰
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
            if not json_match:
                json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', response, re.DOTALL)
            
            if json_match:
                data = json.loads(json_match.group(1) if json_match.groups() else json_match.group())
                
                x_val = data.get('x', 0)
                y_val = data.get('y', 0)
                
                # è½‰æ›ç‚ºæµ®é»æ•¸ä¸¦é©—è­‰åˆç†æ€§
                try:
                    x_float = float(x_val)
                    y_float = float(y_val)
                except (ValueError, TypeError):
                    self._log('warning', f"ç„¡æ³•è½‰æ›åº§æ¨™å€¼: x={x_val}, y={y_val}")
                    return VLMResult(
                        success=False,
                        description=f"åº§æ¨™å€¼æ ¼å¼éŒ¯èª¤: x={x_val}, y={y_val}",
                        raw_response=response
                    )
                
                # é©—è­‰åº§æ¨™åˆç†æ€§ï¼ˆä¸æ‡‰è©²è¶…é 10000 åƒç´ ï¼Œé€šå¸¸è¢å¹•å¯¬åº¦ä¸è¶…é 7680ï¼‰
                # å¦‚æœåº§æ¨™ç•°å¸¸å¤§ï¼Œå¯èƒ½æ˜¯è§£æéŒ¯èª¤æˆ–æ¨¡å‹è¼¸å‡ºæ ¼å¼å•é¡Œ
                MAX_REASONABLE_COORD = 10000
                if abs(x_float) > MAX_REASONABLE_COORD or abs(y_float) > MAX_REASONABLE_COORD:
                    self._log('warning', f"VLM è¿”å›çš„åº§æ¨™ç•°å¸¸å·¨å¤§: x={x_float}, y={y_float}ï¼Œå¯èƒ½æ˜¯è§£æéŒ¯èª¤ã€‚åŸå§‹å›æ‡‰: {response[:500]}")
                    # å¦‚æœåº§æ¨™ç•°å¸¸ï¼Œæ¨™è¨˜ç‚ºå¤±æ•—
                    return VLMResult(
                        success=False,
                        x=0,
                        y=0,
                        confidence=0,
                        description=f"åº§æ¨™å€¼ç•°å¸¸: x={x_float}, y={y_float}",
                        raw_response=response
                    )
                
                # åˆ¤æ–·åº§æ¨™æ ¼å¼ï¼šå¦‚æœå€¼åœ¨ 0-1 ä¹‹é–“ï¼ˆæ¯”ä¾‹åº§æ¨™ï¼‰ï¼Œéœ€è¦è½‰æ›
                # ä½†éœ€è¦åœ–ç‰‡å°ºå¯¸æ‰èƒ½è½‰æ›ï¼Œæ‰€ä»¥å…ˆä¿ç•™åŸå§‹å€¼ï¼Œåœ¨ find_element ä¸­è™•ç†
                # é€™è£¡å…ˆæ¨™è¨˜ç‚ºæµ®é»æ•¸ï¼Œå¦‚æœå°æ–¼ 1 å‰‡èªç‚ºæ˜¯æ¯”ä¾‹åº§æ¨™
                
                # è§£æé‚Šç•Œæ¡†ï¼ˆboxï¼‰
                box = None
                if 'box' in data and data['box']:
                    try:
                        box_list = data['box']
                        if isinstance(box_list, list) and len(box_list) == 4:
                            # box æ ¼å¼: [xmin, ymin, xmax, ymax]
                            box = tuple(map(float, box_list))
                    except (ValueError, TypeError) as e:
                        self._log('debug', f"ç„¡æ³•è§£æ box åº§æ¨™: {e}")
                
                return VLMResult(
                    success=data.get('found', False),
                    x=x_float,  # ä¿ç•™ç‚ºæµ®é»æ•¸ï¼Œä»¥ä¾¿åˆ¤æ–·æ˜¯æ¯”ä¾‹é‚„æ˜¯åƒç´ 
                    y=y_float,  # ä¿ç•™ç‚ºæµ®é»æ•¸ï¼Œä»¥ä¾¿åˆ¤æ–·æ˜¯æ¯”ä¾‹é‚„æ˜¯åƒç´ 
                    confidence=float(data.get('confidence', 0)),
                    description=data.get('description', ''),
                    raw_response=response,
                    box=box  # é‚Šç•Œæ¡†ï¼ˆå¯èƒ½æ˜¯æ¯”ä¾‹åº§æ¨™æˆ–åƒç´ åº§æ¨™ï¼Œéœ€è¦åœ¨ find_element ä¸­è½‰æ›ï¼‰
                )
        except (json.JSONDecodeError, ValueError) as e:
            self._log('debug', f"è§£æ VLM å›æ‡‰å¤±æ•—: {e}")
        
        return VLMResult(
            success=False,
            description=f"ç„¡æ³•è§£æå›æ‡‰: {response[:200]}",
            raw_response=response
        )
    
    def get_stats_summary(self) -> str:
        """å–å¾—çµ±è¨ˆæ‘˜è¦"""
        hit_rate = (self.stats['hits'] / self.stats['attempts'] * 100) if self.stats['attempts'] > 0 else 0
        avg_time = (self.stats['total_time'] / self.stats['hits']) if self.stats['hits'] > 0 else 0
        
        return f"""
[VLM Stats] {self.backend}/{self.model}
  Attempts: {self.stats['attempts']}
  Hits: {self.stats['hits']} ({hit_rate:.1f}%)
  Avg Time: {avg_time:.0f}ms
"""


# å…¨åŸŸå¯¦ä¾‹
_vlm_recognizer = None

def get_vlm_recognizer(backend: str = None, model: str = None) -> VLMRecognizer:
    """å–å¾— VLM è¾¨è­˜å™¨å¯¦ä¾‹"""
    global _vlm_recognizer
    
    # å¾ç’°å¢ƒè®Šæ•¸è®€å–è¨­å®š
    if backend is None:
        backend = os.environ.get('VLM_BACKEND', 'ollama')
    if model is None:
        model = os.environ.get('VLM_MODEL', None)
    
    if _vlm_recognizer is None or _vlm_recognizer.backend != backend:
        _vlm_recognizer = VLMRecognizer(backend=backend, model=model)
    
    return _vlm_recognizer
